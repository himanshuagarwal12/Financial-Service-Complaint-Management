{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('Consumer_complaints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['Consumer complaint narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Consumer complaint narrative'].value_counts().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df=df1.sample(frac=0.1,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Company'].value_counts(dropna=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Product'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Sub-issue'].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Issue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Company public response'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Company response to consumer'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Tags'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Date received'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Date received'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Submitted via'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Timely response?'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Consumer disputed?'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp= pd.crosstab(df['Product'], df['Consumer disputed?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp.plot(kind='bar',figsize=(8,6))## The disputed percentages are about same between \n",
    "###Consent and Consent Not \"complaint narrative text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp1= pd.crosstab(df['Company response to consumer'], df['Consumer disputed?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp1.plot(kind='bar',figsize=(8,6)) ###Most cases are fall in closed with explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp3= pd.crosstab(df['Product'], df['Consumer disputed?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp3.plot(kind='bar',figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##plt.hist(np.log(df['Company'].value_counts()))\n",
    "##plt.xlabel(df['Company'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['State'].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Date received']=pd.DatetimeIndex(df['Date received'],format='%m/%d/%Y').date\n",
    "df['Date sent to company']=pd.DatetimeIndex(df['Date sent to company'],format='%m/%d/%Y').date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['Date received']!=df['Date sent to company']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[pd.isnull(df['Issue'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Sub-product'].fillna('Not Provided',inplace=True)\n",
    "df['Sub-issue'].fillna('Not Provided',inplace=True)\n",
    "df['Consumer complaint narrative'].fillna('None or Not Provided',inplace=True)\n",
    "###Combine \"company public missing value\" with \"Company chose not to provide\"\n",
    "df['Company public response'].fillna('Company chooses not to provide',inplace=True) \n",
    "\n",
    "###Combine missing value of \"Issue\" with \"Other\"\n",
    "df['Issue'].fillna('Other',inplace=True) \n",
    "\n",
    "### Replace missing vlaues of 'Tags' with \"'Unknown'\n",
    "df['Tags'].fillna('Unknown',inplace=True) \n",
    "\n",
    "### Replace missing vlaues of 'Submitted via' with \"'other'\n",
    "df['Submitted via'].fillna('Other',inplace=True) \n",
    "\n",
    "###Combine missing value,other,and withdrawn of \"Consumer consent provided? \" \n",
    "###with Consumer consent not provided, since only users's complaints narrative will be provided\n",
    "### with the type of Consumer consent provided\n",
    "df['Consumer consent provided?'].fillna('Consent not provided',inplace=True) \n",
    "df['Consumer consent provided?']=df['Consumer consent provided?'].apply(lambda x: \n",
    "            'Consent not provided' if x=='Other' or x=='Consent withdrawn' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Fill missing 'State' info using valide zipcode.\n",
    "from pyzipcode import ZipCodeDatabase\n",
    "zip=ZipCodeDatabase()\n",
    "for i in df[pd.isnull(df['State'])&pd.notnull(df['ZIP code'])].index:\n",
    "    try:\n",
    "        df['State'][i]=str(zip[df['ZIP code'][i]].state)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[pd.isnull(df['State'])&pd.isnull(df['ZIP code'])].shape ###Still 4268 users has no state info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['State'].fillna('Not provided',inplace=True)\n",
    "df['ZIP code'].fillna('Not Provided',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Consumer consent provided?'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.groupby(df['Consumer disputed?'])['Date received']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replace={'Yes':True, 'No':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Consumer disputed?']= df['Consumer disputed?'].apply(lambda x: replace[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace1={'Consent provided':True, 'Consent not provided':False}\n",
    "df['Consumer consent provided?']= df['Consumer consent provided?'].apply(lambda x: replace1[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##process time refers to days between the date CFPB received complaitns and the date \n",
    "##when complaints were sent to company on behal of comsume\n",
    "df['Process time']=(df['Date sent to company']-df['Date received']).astype('timedelta64[D]').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create bin variabe of process time\n",
    "process_days_bin = [0,3, 10, 30, 290]\n",
    "process_days_cut = pd.cut(df['Process time'], process_days_bin, right=True, include_lowest=True)\n",
    "df['process_days_bin'] = process_days_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Timely response?'] = df['Timely response?'].apply(lambda x: replace[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company_complaitns_counts = df['Company'].value_counts()\n",
    "df['company_complaint_counts'] = df['Company'].apply(lambda x: company_complaitns_counts[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create bin variable for counts of complaints of each company\n",
    "company_user_bin = [1,1000, 2000, 3000, 3750]\n",
    "company_cut = pd.cut(df['company_complaint_counts'], company_user_bin, right=True, include_lowest=True)\n",
    "df['company_complaint_counts_bin'] = company_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Build dummy variable for all selected category variables in the dataset\n",
    "def get_dummy_table(data,column_names):\n",
    "    df_new=DataFrame()\n",
    "    for name in column_names:\n",
    "        data[name].astype('category')\n",
    "        df_dum=pd.get_dummies(data[name])\n",
    "        df_new=pd.concat([df_new,df_dum], axis=1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_for_model=['Product', 'Sub-product','Issue','Sub-issue', 'Company public response','Tags',\n",
    "                 'Submitted via','Company response to consumer','company_complaint_counts_bin','process_days_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Cancat the created dummy table with other selected feature to build final feature table\n",
    "df_model= get_dummy_table(df,dummy_for_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_model=pd.concat([df_model,df['Process time']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_model=pd.concat([df_model,df['Consumer consent provided?']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_model=pd.concat([df_model,df['Timely response?']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Create features about complaint submitted time\n",
    "df_model['Date_received_year'] = df['Date received'].apply(lambda x: x.year)\n",
    "df_model['Date_received_month'] = df['Date received'].apply(lambda x: x.month)\n",
    "df_model['Date_received_day'] = df['Date received'].apply(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create features about 'Consumenr complaint narrative'\n",
    "\n",
    "from string import punctuation, ascii_letters\n",
    "\n",
    "def process_text_field(text):\n",
    "    '''\n",
    "    text: string\n",
    "    OUTPUT: int, int, int, float (length, word count, uppercase_count_rate, punctuation_rate)\n",
    "    '''\n",
    "    length = len(text)\n",
    "    word_count = 0\n",
    "    last_char = False\n",
    "    for c in text:\n",
    "        if c in ascii_letters:\n",
    "            if last_char==False:\n",
    "                word_count += 1\n",
    "                last_char=True\n",
    "        else:\n",
    "            last_char = False\n",
    "    \n",
    "    punct_count = 0\n",
    "    uppercase_count = 0\n",
    "    for c in text:\n",
    "        if c in punctuation:\n",
    "            punct_count += 1\n",
    "        if c.isupper():\n",
    "            uppercase_count += 1\n",
    "    punctuation_rate = punct_count / float(length+1)\n",
    "    uppercase_count_rate = uppercase_count / float(length+1)\n",
    "    \n",
    "    return length, word_count, uppercase_count_rate, punctuation_rate\n",
    "\n",
    "def process_text_column(df, fieldname):\n",
    "    length_list = []\n",
    "    word_count_list = []\n",
    "    punctuation_rate_list = []\n",
    "    uppercase_count_rate_list=[]\n",
    "    for row_ix in df.index:\n",
    "        length, word_count, uppercase_count_rate, punctuation_rate = process_text_field(df[fieldname][row_ix])\n",
    "        length_list.append(length)\n",
    "        word_count_list.append(word_count)\n",
    "        uppercase_count_rate_list.append(uppercase_count_rate)\n",
    "        punctuation_rate_list.append(punctuation_rate)\n",
    "    return length_list, word_count_list, uppercase_count_rate_list, punctuation_rate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length_list, word_count_list, uppercase_count_rate_list, punctuation_rate_list = process_text_column(df, 'Consumer complaint narrative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_model['complaint_length'] = length_list\n",
    "df_model['complaint_wordcount'] = word_count_list\n",
    "df_model['complaint_uppercaserate'] = uppercase_count_rate_list\n",
    "df_model['complaint_punctuationrate'] = punctuation_rate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_model.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import interp\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed=[]\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_word = df['Consumer complaint narrative'].values\n",
    "y = df['Consumer disputed?'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_word, X_test_word, y_train, y_test = train_test_split(X_word, y, test_size=0.20, random_state=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vectorize and sclae train / test data, respeoctively.\n",
    "vectorizer = TfidfVectorizer(stop_words='english',lowercase=False, min_df=0.001, max_df = 0.2,\n",
    "                             max_features=5000)\n",
    "words_matrix = vectorizer.fit_transform(X_word)\n",
    "words_matrix_test = vectorizer.transform(X_test_word)\n",
    "words_matrix_train = vectorizer.transform(X_train_word)\n",
    "\n",
    "#scale= MaxAbsScaler().fit(words_matrix_train)\n",
    "#X_train_word_scale=scale.transform(words_matrix_train)\n",
    "#X_test_word_scale=scale.transform(words_matrix_test)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(words_matrix_train, y_train)\n",
    "\n",
    "\n",
    "#Combine MultinomialNB() model of 'Consumer complaint narrative' prediction probability with other features\n",
    "df_model['bayes_prob_narrative']= model.predict_proba(words_matrix)[:,1]\n",
    "\n",
    "##Model evaluation via 'Consumer complaint narrative' only\n",
    "\n",
    "model.score(words_matrix_test,y_test)\n",
    "skm.roc_auc_score(y_test, model.predict_proba(words_matrix_test)[:, 1])\n",
    "#skm.recall_score(y_test, model1.predict(X_test_word_scale))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nmf topic extraction\n",
    "aucls=[]\n",
    "for n in [20,100,500,1000]:\n",
    "    nmf = NMF(n_components = n, random_state=1, alpha=.1, l1_ratio=.5).fit(words_matrix)\n",
    "    X_nmf = nmf.transform(words_matrix)\n",
    "    X_train_nmf, X_test_nmf, y_train, y_test = train_test_split(X_nmf, y, test_size=0.20, random_state=67)\n",
    "    rfc = RandomForestClassifier(n_estimators=1000, n_jobs=-1, class_weight='auto')\n",
    "    rfc.fit(X_train_nmf, y_train)\n",
    "    auc = skm.roc_auc_score(y_test, rfc.predict_proba(X_test_nmf)[:, 1])\n",
    "    aucls.append(auc)\n",
    "aucls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tfidf_feature_names = vectorizer.get_feature_names()\n",
    "#print_top_words(nmf, tfidf_feature_names, n_top_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nmf.transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_nmf, X_test_nmf, y_train, y_test = train_test_split(X_nmf, y, test_size=0.20, random_state=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=1000, n_jobs=-1, class_weight='auto')\n",
    "rfc.fit(X_train_nmf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc.score(X_test_nmf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skm.roc_auc_score(y_test, rfc.predict_proba(X_test_nmf)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LatentDirichletAllocation topic extration\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(X_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=10, max_iter=20,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_model.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_curve(probabilities, labels):\n",
    "    '''\n",
    "    INPUT: numpy array, numpy array\n",
    "    OUTPUT: list, list, list\n",
    "\n",
    "    Take a numpy array of the predicted probabilities and a numpy array of the\n",
    "    true labels.\n",
    "    Return the True Positive Rates, False Positive Rates and Thresholds for the\n",
    "    ROC curve.\n",
    "    '''\n",
    "\n",
    "    thresholds = np.sort(probabilities)\n",
    "\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "\n",
    "    num_positive_cases = sum(labels)\n",
    "    num_negative_cases = len(labels) - num_positive_cases\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        # With this threshold, give the prediction of each instance\n",
    "        predicted_positive = probabilities >= threshold\n",
    "        # Calculate the number of correctly predicted positive cases\n",
    "        true_positives = np.sum(predicted_positive * labels)\n",
    "        # Calculate the number of incorrectly predicted positive cases\n",
    "        false_positives = np.sum(predicted_positive) - true_positives\n",
    "        # Calculate the True Positive Rate\n",
    "        tpr = true_positives / float(num_positive_cases)\n",
    "        # Calculate the False Positive Rate\n",
    "        fpr = false_positives / float(num_negative_cases)\n",
    "\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "    \n",
    "    return tprs, fprs, thresholds.tolist()\n",
    "\n",
    "def plot_roc(probs, y_true, title, xlabel, ylabel):\n",
    "    # ROC\n",
    "    tpr, fpr, thresholds = roc_curve(v_probs, y_test)\n",
    "\n",
    "    plt.hold(True)\n",
    "    plt.plot(fpr, tpr)\n",
    "\n",
    "    # 45 degree line\n",
    "    xx = np.linspace(0, 1.0, 20)\n",
    "    plt.plot(xx, xx, color='red')\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='auto')\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_probs = lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc(v_probs, y_test, \"ROC plot of  complaint dispute\", \n",
    "         \"False Positive Rate (1 - Specificity)\", \"True Positive Rate (Sensitivity, Recall)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n",
    "skm.roc_auc_score(y_test, v_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skm.recall_score(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(model, X_test, y_true):\n",
    "    cm = confusion_matrix(y_true, model.predict(X_test))\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    # Show confusion matrix in a separate window\n",
    "    plt.matshow(cm)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argsort(lr.coef_)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_column = df_model.columns[np.argsort(lr.coef_)[::-1]][0][:245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_column.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_sub_column = df_model[sub_column]\n",
    "X_sub_train, X_sub_test, y_train, y_test = train_test_split(X_sub_column, y, test_size=0.20, random_state=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_sub = LogisticRegression(class_weight='auto')\n",
    "lr_sub.fit(X_sub_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_sub.score(X_sub_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skm.roc_auc_score(y_test,lr_sub.predict_proba(X_sub_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try descision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gradiend Boosting Classifier\n",
    "#from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gbc = GradientBoostingClassifier(n_estimators=1000, max_depth=8, subsample=0.5, \n",
    "                             #   max_features='auto', learning_rate=0.01)\n",
    "#gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gbc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.crosstab(y_test, gbc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(gbc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#skm.roc_auc_score(y_test, gbc.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=3000, n_jobs=-1, class_weight='auto')\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(y_test, rfc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skm.roc_auc_score(y_test, rfc.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skm.recall_score(y_test, rfc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_importance(clf, X, max_features=10):\n",
    "    '''Plot feature importance'''\n",
    "    feature_importance = clf.feature_importances_\n",
    "    # make importances relative to max importance\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    \n",
    "    # Show only top features\n",
    "    pos = pos[-max_features:]\n",
    "    feature_importance = (feature_importance[sorted_idx])[-max_features:]\n",
    "    feature_names = (X.columns[sorted_idx])[-max_features:]\n",
    "    \n",
    "    plt.barh(pos, feature_importance, align='center')\n",
    "    plt.yticks(pos, feature_names)\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Variable Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_importance(rfc, df_model, max_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
